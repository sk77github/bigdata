Hadoop并不是什么数据库，也不是程序库，甚至不是一个独立产品。实际上，Hadoop是一些独立模块的组合，
包括一个分布式文件系统HDFS、
一个大型分布式数据处理库MapReduce，
一个分布式数据库HBase、等等等等。做一个类比的话，就好像是Microsoft Office，其实我们并没有一个叫做Office的应用，Office实际上指的是Word、Excel等一系列桌面应用的组合。

 HDFS和MR共同组成Hadoop分布式系统体系结构的核心。
 HDFS在集群上实现了分布式文件系统，
 MR在集群上实现了分布式计算和任务处理。
 HDFS在MR任务处理过程中提供了文件操作和存储等支持，MR在HDFS的基础上实现了任务的分发、跟踪、执行等工作，并收集结果，
 二者相互作用，完成分布式集群的主要任务。
 
 
 Hbase就是Hadoop database。
 
 
  Hive是建立在Hadoop上的数据仓库基础架构。它提供了一系列的工具，用来进行数据提取、转换、加载，这是一种可以存储、查询
  和分析存储在Hadoop中的大规模数据机制。可以把Hadoop下结构化数据文件映射为一张成Hive中的表，并提供类sql查询功能，
  除了不支持更新、索引和事务，sql其它功能都支持。
  
 补充MapReduce的不足：
Apache Pig也是Hadoop框架中的一部分，Pig提供类SQL语言（Pig Latin）通过MapReduce来处理大规模半结构化数据。
而Pig Latin是更高级的过程语言，通过将MapReduce中的设计模式抽象为操作，如Filter，GroupBy，Join，OrderBy，
由这些操作组成有向无环图（DAG）.而Pig Latin又是通过编译为MapReduce，在Hadoop集群上执行的

有了MapReduce，Tez和Spark之后，程序员发现，MapReduce的程序写起来真麻烦。
他们希望简化这个过程。这就好比你有了汇编语言，虽然你几乎什么都能干了，但是你还是觉得繁琐。
你希望有个更高层更抽象的语言层来描述算法和数据处理流程。于是就有了Pig和Hive。Pig是接近脚本方式去描述MapReduce，
Hive则用的是SQL。它们把脚本和SQL语言翻译成MapReduce程序，丢给计算引擎去计算，而你就从繁琐的MapReduce程序中解脱出来，
用更简单更直观的语言去写程序了。

底层HDFS，上面跑MapReduce／Tez／Spark，在上面跑Hive，Pig。这解决了中低速数据处理的要求。
  
 
